{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "This script will import data into a dataframe called *data*. \n",
    "\n",
    "The folder containing the measurement results contains a single *csv* file. This csv file contains two sections; the hirst rows contains general information regarding the measurement (voltage, magnification, etc.) whereas the second part contains a list of discover particles with the collected data. \n",
    "\n",
    "In order to import the data, at first, the first (and only) csv file in the main directory is searched and opened ([Search CSV](#Search-CSV)). Then the headers are read ([Headers](#Headers)) one line at a time and if the line contains important information, this information is loaded in. The single line scanning continues until the column headers are identified. These headers are temporarily stored after which the remaining particle data is loaded ([Particle data](#Particle-data)) into an array. To better handle the data, the stored column names are assigned to the array into a dataframe. Finally, only particles from the given stub are selected ([Stub selection](#Stub-selection)). In order to prepare the data for some future usage, some columns are copied into new columns ([Special data columns](#Special-data-columns))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation\n",
    "As this script is designed for external use but should also be usable stand-alone, a number of variables assigned with standard values in case they do not yet exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory\n",
    "try:\n",
    "    directory\n",
    "except NameError:\n",
    "    directory = \"F:\\\\PA_UC\\\\\"\n",
    "    print(\"Directory not specified, set to \"+directory)\n",
    "\n",
    "# stub\n",
    "try:\n",
    "    stub\n",
    "except NameError:\n",
    "    stub = 1\n",
    "    print(\"Stub not specified, set to \"+str(stub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search CSV\n",
    "At first, the last (and only) csv file in the directory is selected and returned into the variable *file*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: F:\\PA_UC\\pa_uc.csv\n"
     ]
    }
   ],
   "source": [
    "for i in listdir(directory):\n",
    "    if i.endswith(\".csv\"):\n",
    "        file = directory+i\n",
    "\n",
    "print(\"File: \"+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Headers\n",
    "Then, the file is opened and the headers are scanned. For a number of headers, the data is printed (like magnification and voltage), others are skipped. Finally, the line containing the column names is found (starting with *Part#*). This line is read, split based on commas and spaces are removed. This list will be used later. Also, the number of lines to skip before reaching the particle data is now known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 13.12.2016\n",
      "Voltage: 10.0 kV\n",
      "Magnification: 2500x\n",
      "Measurement time: 30.0 s\n",
      "Number of columns: 28\n"
     ]
    }
   ],
   "source": [
    "with open(file) as f:\n",
    "    for i in range(0, 20):\n",
    "        line = f.readline().replace(\"\\n\", \"\").split(',')\n",
    "        if(line[0].strip()==\"Part#\"):\n",
    "            columns = line\n",
    "            skip=i+1\n",
    "        elif(line[0].strip()==\"Date\"):\n",
    "            print(\"Date: \"+str(line[2].strip())+\".\"+str(line[1].strip())+\".\"+str(line[3].strip()))\n",
    "        elif(line[0].strip()==\"Acc.\"):\n",
    "            print(\"Voltage: \"+str(line[2].strip())+\" kV\")\n",
    "        elif(line[0].strip()==\"Magn:\"):\n",
    "            print(\"Magnification: \"+str(line[1].strip())+\"x\")\n",
    "        elif(line[0].strip()==\"Preset\"):\n",
    "            print(\"Measurement time: \"+str(line[2].strip())+\" s\")\n",
    "\n",
    "print('Number of columns: '+str(len(columns)))\n",
    "for i in range(len(columns)):\n",
    "    columns[i] = columns[i].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Particle data\n",
    "The particle data is present as a long list, with a single particle on each line and the data separated by commas. The whole list is loaded into a numpy array. The array is then converted into a pandas dataframe using the previously obtained column names as header. This allows columns to be selected more easily, especially since the columns differ sometimes between measurements (mostly due to selected EDX elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of particles: 3639\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(file, delimiter=',', skiprows=skip, comments='_')\n",
    "print(\"Number of particles: \"+str(len(data)))\n",
    "\n",
    "# Transfer data into a dataframe\n",
    "data = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stub selection\n",
    "Since a particle analysis can be performed over multiple samples (*stubs*), only a single stub is imported. Therefore, the dataframe is expended with the stub and field number after which only the particles from the selected stub are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particles on stub 1: 829\n"
     ]
    }
   ],
   "source": [
    "# Get stub for each particle\n",
    "data[\"stub\"] = np.rint(np.floor(data[\"Field#\"]/10000))\n",
    "\n",
    "# Only select particles from selected strub\n",
    "data = data[data[\"stub\"]==stub]\n",
    "\n",
    "# Get field number\n",
    "data[\"fieldnum\"] = np.rint(np.floor(data[\"Field#\"]-10000*stub))\n",
    "\n",
    "print(\"Particles on stub \"+str(stub)+\": \"+str(len(data)))\n",
    "\n",
    "#print(\"Number of fields: \"+str(len()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special data columns\n",
    "In order to prepare the data for some future functions (e.g. ImageJ particle analysis and particle relocalization), some data is copied into specific columns. At present, the following columns are copied:\n",
    "- *X* <- *StgX* : To be used for relozalization (e.g. apply translation and rotation)\n",
    "- *Y* <- *StgY* : To be used for relozalization (e.g. apply translation and rotation)\n",
    "- *d* <- *AvgDiam* : To be used for alternative calculations (e.g. ImageJ)\n",
    "- *A* <- *Aspe* : To be used for alternative calculations (e.g. ImageJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"X\"] = data[\"StgX\"]\n",
    "data[\"Y\"] = data[\"StgY\"]\n",
    "data[\"d\"] = data[\"AvgDiam\"]\n",
    "data[\"A\"] = data[\"Aspe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just to test some output options:\n",
    "#from IPython.display import HTML\n",
    "#HTML(data.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
